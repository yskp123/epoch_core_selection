{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7258fdbc-0db9-4ddb-9730-b430925ee320",
   "metadata": {},
   "source": [
    "# Task 2 - CV + NLP Sentiment Analysis of Handwritten Text Using Custom-built OCR and Sentiment Classification Models\n",
    "The primary objective of this project is to use artificial intelligence to convert handwritten text images into digital text and subsequently perform sentiment analysis on the extracted text. The project will leverage the provided labelled dataset of handwritten alphabets (alphabets_dataset.zip) and the sentiment analysis dataset (sentiment_analysis_dataset.csv). Use of pre-trained models is not allowed. Finally, the performance is to be tested and reported on the images provided in the target_images\n",
    "folder (whose labels are in target_labels.csv).\n",
    "## Answer:\n",
    "The following code snippet is responsible for creating and training a convolutional neural network (CNN) model to recognize handwritten characters from images of letters A-Z\n",
    "- The models.Sequential function initializes a sequential model, allowing layers to be added in sequence.\n",
    "- layers.Input(shape=(28, 28, 1)) specifies the input shape for each image, which is 28x28 pixels with 1 channel (grayscale).\n",
    "- layers.Conv2D(32, (3, 3), activation='relu') adds a 2D convolutional layer with 32 filters of size 3x3, using ReLU activation function.\n",
    "- layers.MaxPooling2D((2, 2)) adds a max pooling layer with pool size 2x2, which reduces spatial dimensions to capture the most important features.\n",
    "- layers.Conv2D(64, (3, 3), activation='relu') adds another convolutional layer with 64 filters of size 3x3 and ReLU activation.\n",
    "- Another layers.MaxPooling2D((2, 2)) follows to further downsample the feature maps.\n",
    "- layers.Flatten() flattens the 2D feature maps into a 1D vector to prepare for fully connected layers.\n",
    "- layers.Dense(128, activation='relu') adds a fully connected layer with 128 neurons and ReLU activation.\n",
    "- layers.Dense(26, activation='softmax') adds the output layer with 26 neurons (one for each letter from A to Z), using softmax activation to output probabilities of each class.\n",
    "\n",
    "Finally save it as handwritten.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955218f-f9b0-4118-a899-d6477fd9fba4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_handwritten_data_from_zip(zip_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        # Extract and read the CSV file\n",
    "        with zip_ref.open('alphabet_labels.csv') as csvfile:\n",
    "            labels_df = pd.read_csv(csvfile)\n",
    "        \n",
    "        # Create a dictionary from the CSV file\n",
    "        label_dict = dict(zip(labels_df['file'], labels_df['label']))\n",
    "\n",
    "        for file_name in zip_ref.namelist():\n",
    "            if file_name.endswith('.png'):  # Adjust if images are in a different format\n",
    "                image_name = os.path.basename(file_name)\n",
    "                if image_name in label_dict:\n",
    "                    label = label_dict[image_name]\n",
    "                    if len(label) == 1:  # Ensure the label is a single character\n",
    "                        with zip_ref.open(file_name) as file:\n",
    "                            # Read image from the file\n",
    "                            image = np.frombuffer(file.read(), np.uint8)\n",
    "                            image = cv2.imdecode(image, cv2.IMREAD_GRAYSCALE)\n",
    "                            image = cv2.resize(image, (28, 28))  # Resize to 28x28 pixels\n",
    "                            images.append(image)\n",
    "                            labels.append(ord(label) - ord('A'))  # Convert character to numerical value\n",
    "                    else:\n",
    "                        print(f\"Skipping file with invalid label: {file_name}\")\n",
    "                else:\n",
    "                    print(f\"Skipping file with no matching label: {file_name}\")\n",
    "\n",
    "    images = np.array(images).reshape(-1, 28, 28, 1) / 255.0\n",
    "    labels = np.array(labels)\n",
    "    return images, labels\n",
    "\n",
    "# Load images and labels from the ZIP file\n",
    "images, labels = load_handwritten_data_from_zip('alphabets_dataset.zip')\n",
    "\n",
    "if len(images) == 0:\n",
    "    print(\"No valid images found. Please check the dataset and label extraction logic.\")\n",
    "else:\n",
    "    # Create and train the model\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(28, 28, 1)),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(26, activation='softmax')  # 26 classes for A-Z\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(images, labels, epochs=10, validation_split=0.2)\n",
    "    model.save('handwritten.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a4ebce-b2ab-4c57-9c41-29ab8fa0300f",
   "metadata": {},
   "source": [
    "Now, we need to get sentences from the images using the model we created and find the sentiment by training and testing it here.\n",
    "1. Image Processing:\n",
    "    - preprocess_image(image_path): Reads an image, converts it to grayscale, applies Gaussian blur, and thresholds it to create a binary image (binary)\n",
    "    - detect_text_regions(binary_image): Labels connected components in the binary image and identifies bounding boxes around them.\n",
    "    - recognize_text(image, bounding_boxes, model): Extracts each character from identified bounding boxes, preprocesses them for the Keras model, makes predictions, and converts predictions into characters.\n",
    "2. Training Sentiment Analysis Models:\n",
    "   - Splits the dataset into training and testing sets for each sentiment category ('Angry', 'Happy', 'Neutral').\n",
    "   - Trains three Naive Bayes classifiers (clf_angry, clf_neutral, clf_happy) using the TF-IDF transformed data\n",
    "3. Processing and Analysis:\n",
    "   - draw_and_group_boxes(image_paths, output_paths): Processes multiple images (image_paths), detects text regions, recognizes characters, and groups them into meaningful text units (grouped_texts). It also draws bounding boxes around recognized characters on the original images and saves them to specified paths (output_paths)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f78e843-031f-4dc1-8422-4b0c1f936fc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/skp123/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1: lonnaulo xylysxys aatvxaxx nvayxwpsm nxnoouspn ollyryut xxnxcxysl ncourmuav loxulnox lcmpvoym\n",
      "Can't predict the sentiment\n",
      "Line 2: lyccsymo oranuytwxym xlxsutpx plxxnyzy aoxuosalcyw xlmulncxl wxxxauxa mnlcxyws ucovuxxo svxsxxar\n",
      "Can't predict the sentiment\n",
      "Line 3: zuxuxsyxt xlncxcam pbcumnlma musxlcxp asxxarxol mmxylsbt ylcbsarm xnrynatvc xyvclbwuz clsrarx\n",
      "Can't predict the sentiment\n",
      "Line 4: llsxxpxm unpnynxct sxtrwaou yumsmmmcu sxnsollz xnpxupxymu wapsxwxmr rywnnuru auuaxpcm suvxsanyt\n",
      "Can't predict the sentiment\n",
      "Line 5: sxmyvsyll ouvolxvt samacuxx rtvrlyuwx ommnorxlx llnuyoxaxxx nxtltxuxnnx mmuryapam lusxrruxx oonuacrx\n",
      "Can't predict the sentiment\n",
      "Line 6: vsyclxavx avxoaaawcxsxlx cmxosluryt xulpsllu mnpclnlnx rxuulucao btrmcwyxx clwuyvnxam pxynnaxsm xurlcaxccxx\n",
      "Can't predict the sentiment\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.ndimage import label\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "import contextlib\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Suppress TensorFlow/Keras messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"sentiment_analysis_dataset.csv\")\n",
    "\n",
    "# Mapping sentiments to binary labels\n",
    "y_angry = df['sentiment'].map({'Angry': 1, 'Happy': 0, 'Neutral': 0})\n",
    "y_neutral = df['sentiment'].map({'Angry': 0, 'Happy': 0, 'Neutral': 1})\n",
    "y_happy = df['sentiment'].map({'Angry': 0, 'Happy': 1, 'Neutral': 0})\n",
    "\n",
    "# Initialize stopwords set and convert it to a list\n",
    "stopset = set(stopwords.words('english'))\n",
    "stop_words_list = list(stopset)\n",
    "\n",
    "# Initialize TF-IDF vectorizer with correct stop_words parameter\n",
    "vectorizer = TfidfVectorizer(use_idf=True, lowercase=True, strip_accents='ascii', stop_words=stop_words_list)\n",
    "\n",
    "# Vectorize text data\n",
    "X = vectorizer.fit_transform(df['line'])\n",
    "\n",
    "# Split dataset into training and testing sets for each sentiment category\n",
    "X_train_angry, X_test_angry, y_train_angry, y_test_angry = train_test_split(X, y_angry, random_state=42)\n",
    "X_train_neutral, X_test_neutral, y_train_neutral, y_test_neutral = train_test_split(X, y_neutral, random_state=42)\n",
    "X_train_happy, X_test_happy, y_train_happy, y_test_happy = train_test_split(X, y_happy, random_state=42)\n",
    "\n",
    "# Train Naive Bayes classifiers for each sentiment category\n",
    "clf_angry = naive_bayes.MultinomialNB()\n",
    "clf_angry.fit(X_train_angry, y_train_angry)\n",
    "\n",
    "clf_neutral = naive_bayes.MultinomialNB()\n",
    "clf_neutral.fit(X_train_neutral, y_train_neutral)\n",
    "\n",
    "clf_happy = naive_bayes.MultinomialNB()\n",
    "clf_happy.fit(X_train_happy, y_train_happy)\n",
    "\n",
    "# Load your trained model\n",
    "model = load_model('handwritten.keras')\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found or unable to load.\")\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "    _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return binary\n",
    "\n",
    "def detect_text_regions(binary_image):\n",
    "    labeled_image, num_features = label(binary_image)\n",
    "    bounding_boxes = []\n",
    "    for component in range(1, num_features + 1):\n",
    "        coords = np.column_stack(np.where(labeled_image == component))\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        bounding_boxes.append((x, y, w, h))\n",
    "    return bounding_boxes\n",
    "\n",
    "def recognize_text(image, bounding_boxes, model):\n",
    "    recognized_text = []\n",
    "    for (x, y, w, h) in bounding_boxes:\n",
    "        roi = image[y:y+h, x:x+w]\n",
    "        if roi.size == 0:\n",
    "            continue\n",
    "        roi = cv2.resize(roi, (28, 28))\n",
    "        roi = roi.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "        with open(os.devnull, 'w') as f:\n",
    "            with contextlib.redirect_stdout(f):\n",
    "                prediction = model.predict(roi)\n",
    "        character = chr(np.argmax(prediction) + ord('a'))\n",
    "        recognized_text.append(character)\n",
    "    return recognized_text\n",
    "\n",
    "def draw_and_group_boxes(image_paths, output_paths):\n",
    "    grouped_texts = []\n",
    "\n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        binary_image = preprocess_image(image_path)\n",
    "        bounding_boxes = detect_text_regions(binary_image)\n",
    "        bounding_boxes = sorted(bounding_boxes, key=lambda bb: (bb[0], bb[1]))\n",
    "        recognized_characters = recognize_text(binary_image, bounding_boxes, model)\n",
    "\n",
    "        grouped_text = []\n",
    "        current_word = []\n",
    "        word_distance_threshold = 5\n",
    "        character_idx = 0\n",
    "\n",
    "        for idx, (x, y, w, h) in enumerate(bounding_boxes):\n",
    "            if character_idx >= len(recognized_characters):\n",
    "                break\n",
    "            if idx > 0 and (x > bounding_boxes[idx-1][0] + bounding_boxes[idx-1][2] + word_distance_threshold):\n",
    "                if current_word:\n",
    "                    grouped_text.append(\"\".join(current_word))\n",
    "                    current_word = []\n",
    "            \n",
    "            current_word.append(recognized_characters[character_idx])\n",
    "            character_idx += 1\n",
    "\n",
    "        if current_word:\n",
    "            grouped_text.append(\"\".join(current_word))\n",
    "        \n",
    "        grouped_texts.append(grouped_text)\n",
    "        # Load the original image to display bounding boxes\n",
    "        original_image = cv2.imread(image_path)\n",
    "        # Draw bounding boxes on the original image\n",
    "        for (x, y, w, h) in bounding_boxes:\n",
    "            cv2.rectangle(original_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Save the image with bounding boxes\n",
    "        cv2.imwrite(output_paths[i], original_image)\n",
    "    \n",
    "    return grouped_texts\n",
    "\n",
    "# Example usage\n",
    "image_paths = ['target_images/line_1.png', 'target_images/line_2.png', 'target_images/line_3.png', 'target_images/line_4.png', 'target_images/line_5.png', 'target_images/line_6.png']\n",
    "output_paths = ['split_letters_1.png', 'split_letters_2.png', 'split_letters_3.png', 'split_letters_4.png', 'split_letters_5.png', 'split_letters_6.png']\n",
    "grouped_texts = draw_and_group_boxes(image_paths, output_paths)\n",
    "\n",
    "# Display grouped text as a sentence with spaces in between\n",
    "for idx, text in enumerate(grouped_texts):\n",
    "    sentence = ' '.join(text)\n",
    "    Sentence = vectorizer.transform([sentence])\n",
    "    print(f\"Line {idx+1}: {sentence}\")\n",
    "    # Print predictions for each sentiment category\n",
    "    if clf_angry.predict(Sentence.toarray()) > 0.33:\n",
    "        print(\"Sentiment Prediction: Angry\")\n",
    "    elif clf_neutral.predict(Sentence.toarray()) > 0.33:\n",
    "        print(\"Sentiment Prediction: Neutral\")\n",
    "    elif clf_happy.predict(Sentence.toarray()) > 0.33:\n",
    "        print(\"Sentiment Prediction: Happy\")\n",
    "    else:\n",
    "        print(\"Can't predict the sentiment\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d1b9b7-24d8-46ac-bb1c-0011dc47197c",
   "metadata": {},
   "source": [
    "As we can see the output is not what we expect. The split_letters are near to what we expect but still there are lot of errors and I didn't get the sentiment part. I tried my best to get the output but i wasn't successful :("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
